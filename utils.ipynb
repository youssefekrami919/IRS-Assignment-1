{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf28c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from section1 task 9\n",
    "def get_total_ratings(item_list, ni_dict):\n",
    "    total = 0\n",
    "    for movie_id in item_list:\n",
    "        if movie_id in ni_dict:\n",
    "            total = total + ni_dict[movie_id]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from section1 task 9\n",
    "def quick_sort(arr):\n",
    "    # Base case: if list is empty or has 1 item, it's already sorted\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    \n",
    "    pivot = arr[len(arr) // 2] # Choose middle element as pivot\n",
    "    left = []\n",
    "    middle = []\n",
    "    right = []\n",
    "    \n",
    "    for x in arr:\n",
    "        # Compare the count (index 1 of the inner list)\n",
    "        if x[1] < pivot[1]:\n",
    "            left.append(x)\n",
    "        elif x[1] == pivot[1]:\n",
    "            middle.append(x)\n",
    "        else:\n",
    "            right.append(x)\n",
    "            \n",
    "    # Recursive calls\n",
    "    return quick_sort(left) + middle + quick_sort(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from section1 task 14\n",
    "def manual_intersection_size(set1, set2):\n",
    "    count = 0\n",
    "    for x in set1:\n",
    "        for y in set2:\n",
    "            if x == y:\n",
    "                count += 1\n",
    "                break\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4597f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function \n",
    "# Merge Sort implementation to sort by count\n",
    "def merge_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    \n",
    "    mid = len(arr) // 2\n",
    "    left = merge_sort(arr[:mid])\n",
    "    right = merge_sort(arr[mid:])\n",
    "    \n",
    "    return merge(left, right)\n",
    "\n",
    "def merge(left, right):\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    \n",
    "    while i < len(left) and j < len(right):\n",
    "        # Compare counts (index 1 in tuple)\n",
    "        if left[i][1] <= right[j][1]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "            \n",
    "    # Append leftovers\n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56fffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helper functions ----\n",
    "\n",
    "def common_items(u1_dict, u2_dict):\n",
    "    com = []\n",
    "    for x in u1_dict:\n",
    "        for y in u2_dict:\n",
    "            if x == y:\n",
    "                com.append(x)\n",
    "                break\n",
    "    return com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14553953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# user_user cosine similarity\n",
    "def cosine_similarity(u1_dict, u2_dict):\n",
    "    com = common_items(u1_dict, u2_dict)\n",
    "\n",
    "    if len(com) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    dot = 0.0\n",
    "    for item in com:\n",
    "        dot += u1_dict[item] * u2_dict[item]\n",
    "\n",
    "    norm1 = 0.0\n",
    "    for item in u1_dict:\n",
    "        norm1 += u1_dict[item] * u1_dict[item]\n",
    "\n",
    "    norm2 = 0.0\n",
    "    for item in u2_dict:\n",
    "        norm2 += u2_dict[item] * u2_dict[item]\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    sim = dot / ((norm1**0.5) * (norm2**0.5))\n",
    "    return round(sim, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b7d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def top_20_percent_desc(sorted_list):\n",
    "    n = len(sorted_list)\n",
    "    k = int(n * 0.2)\n",
    "    if k < 1:\n",
    "        k = 1\n",
    "\n",
    "    # Take last k elements (top scores)\n",
    "    top_users = sorted_list[-k:]\n",
    "\n",
    "    # Reverse to make highest first\n",
    "    top_users.reverse()\n",
    "\n",
    "    # Round values INSIDE the list\n",
    "    for i in range(len(top_users)):\n",
    "        uid, sim = top_users[i]\n",
    "        top_users[i] = (uid, round(sim, 2))\n",
    "\n",
    "    return top_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd83762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helper function to predict rating ----\n",
    "def predict_rating(target_user, item, top_sim_users, user_ratings):\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "    \n",
    "    for (other_user, similarity) in top_sim_users:\n",
    "        # Only consider users who rated the item\n",
    "        if item in user_ratings.get(other_user, {}):\n",
    "            r = user_ratings[other_user][item]\n",
    "            numerator += similarity * r\n",
    "            denominator += abs(similarity)  # use abs(similarity) to avoid negative impact\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return None  # Cannot predict without any rating info\n",
    "    \n",
    "    predicted = numerator / denominator\n",
    "    return round(predicted, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b311577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Centered Cosine Similarity function\n",
    "def mean_centered_cosine(u1_dict, u2_dict, u1_mean, u2_mean):\n",
    "    com = common_items(u1_dict, u2_dict)\n",
    "    if len(com) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dot = norm1 = norm2 = 0.0\n",
    "    for item in com:\n",
    "        dev1 = u1_dict[item] - u1_mean\n",
    "        dev2 = u2_dict[item] - u2_mean\n",
    "        dot += dev1 * dev2\n",
    "        norm1 += dev1 ** 2\n",
    "        norm2 += dev2 ** 2\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot / ((norm1 ** 0.5) * (norm2 ** 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(u1_dict, u2_dict, u1_mean, u2_mean):\n",
    "    com = common_items(u1_dict, u2_dict)\n",
    "    if len(com) < 2:  # PCC undefined or zero with less than 2 common items\n",
    "        return 0.0\n",
    "    \n",
    "    sum1 = sum2 = sum1_sq = sum2_sq = sum_prod = 0.0\n",
    "    for item in com:\n",
    "        dev1 = u1_dict[item] - u1_mean\n",
    "        dev2 = u2_dict[item] - u2_mean\n",
    "        sum1 += dev1\n",
    "        sum2 += dev2\n",
    "        sum1_sq += dev1 ** 2\n",
    "        sum2_sq += dev2 ** 2\n",
    "        sum_prod += dev1 * dev2\n",
    "    \n",
    "    numerator = sum_prod\n",
    "    denominator = (sum1_sq * sum2_sq) ** 0.5\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    pcc = numerator / denominator\n",
    "    return round(pcc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5621d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_center(item_dict):\n",
    "    mean_rating = sum(item_dict.values()) / len(item_dict)\n",
    "    centered = {}\n",
    "    for u in item_dict:\n",
    "        centered[u] = item_dict[u] - mean_rating\n",
    "    return centered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_users(i1_dict, i2_dict):\n",
    "    com = []\n",
    "    for u in i1_dict:\n",
    "        if u in i2_dict:\n",
    "            com.append(u)\n",
    "    return com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f914aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_items(i1_dict_raw, i2_dict_raw):\n",
    "    # mean-center the rating vectors\n",
    "    i1_dict = mean_center(i1_dict_raw)\n",
    "    i2_dict = mean_center(i2_dict_raw)\n",
    "\n",
    "    com = common_users(i1_dict, i2_dict)\n",
    "    if len(com) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # dot product\n",
    "    dot = 0.0\n",
    "    for u in com:\n",
    "        dot += i1_dict[u] * i2_dict[u]\n",
    "\n",
    "    # norms\n",
    "    norm1 = sum(v*v for v in i1_dict.values()) ** 0.5\n",
    "    norm2 = sum(v*v for v in i2_dict.values()) ** 0.5\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return round(dot / (norm1 * norm2), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd22bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcc_similarity_items(i1_dict, i2_dict):\n",
    "    # Find common users\n",
    "    com = common_users(i1_dict, i2_dict)\n",
    "    if len(com) < 2:\n",
    "        return 0.0  # PCC undefined for <2 points\n",
    "\n",
    "    # Extract rating vectors\n",
    "    x = [i1_dict[u] for u in com]\n",
    "    y = [i2_dict[u] for u in com]\n",
    "\n",
    "    # Means\n",
    "    mean_x = sum(x) / len(x)\n",
    "    mean_y = sum(y) / len(y)\n",
    "\n",
    "    # Numerator\n",
    "    num = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(len(com)))\n",
    "\n",
    "    # Denominator\n",
    "    den_x = sum((x[i] - mean_x) ** 2 for i in range(len(com))) ** 0.5\n",
    "    den_y = sum((y[i] - mean_y) ** 2 for i in range(len(com))) ** 0.5\n",
    "\n",
    "    if den_x == 0 or den_y == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return round(num / (den_x * den_y), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d6767",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09603b45",
   "metadata": {},
   "source": [
    "Function 1: Count raters per item (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f101e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_raters(df):\n",
    "    num_raters = {}\n",
    "    for _, row in df.iterrows():\n",
    "        item = int(row['movieId'])  # convert to int here\n",
    "        if item not in num_raters:\n",
    "            num_raters[item] = 0\n",
    "        num_raters[item] += 1\n",
    "    return num_raters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b67bb13",
   "metadata": {},
   "source": [
    "Function 2: Compute average rating per item (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7eac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_rating(df):\n",
    "   \n",
    "    rating_sum = {}    # sum of ratings per item\n",
    "    rating_count = {}  # number of ratings per item\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        item = int(row['movieId'])  # ensure item ID is integer\n",
    "        rating = float(row['rating'])  # ensure rating is float\n",
    "\n",
    "        if item not in rating_sum:\n",
    "            rating_sum[item] = 0.0\n",
    "            rating_count[item] = 0\n",
    "\n",
    "        rating_sum[item] += rating\n",
    "        rating_count[item] += 1\n",
    "\n",
    "    # Compute average rating per item as plain float\n",
    "    avg_rating = {}\n",
    "    for item in rating_sum:\n",
    "        avg_rating[item] = float(rating_sum[item] / rating_count[item])\n",
    "\n",
    "    return avg_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eda20f",
   "metadata": {},
   "source": [
    "Function 3: Compute rating standard deviation per item (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_std_rating(df, avg_rating):\n",
    "    rating_values = {}\n",
    "\n",
    "    # Collect all ratings per item\n",
    "    for _, row in df.iterrows():\n",
    "        item = int(row['movieId'])  # convert item ID to integer\n",
    "        rating = float(row['rating'])\n",
    "\n",
    "        \n",
    "        if item not in rating_values:\n",
    "            rating_values[item] = []\n",
    "        rating_values[item].append(rating)\n",
    "\n",
    "    # Compute standard deviation manually\n",
    "    std_rating = {}\n",
    "    for item, values in rating_values.items():\n",
    "        mean = avg_rating[item]\n",
    "        n = len(values)\n",
    "        \n",
    "        if n == 1:\n",
    "            std_rating[item] = 0  # no variation for single rating\n",
    "            continue\n",
    "\n",
    "        variance_sum = 0\n",
    "        for x in values:\n",
    "            variance_sum += (x - mean) ** 2\n",
    "\n",
    "        variance = variance_sum / n\n",
    "        std_rating[item] = math.sqrt(variance)\n",
    "\n",
    "    return std_rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ead91",
   "metadata": {},
   "source": [
    "function 4: Build the item feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_features(num_raters, avg_rating, std_rating):\n",
    "    features = {}\n",
    "\n",
    "    for item in num_raters.keys():\n",
    "        item_int = int(item)  # ensure item ID is an integer\n",
    "        features[item_int] = [\n",
    "            num_raters[item_int],\n",
    "            avg_rating[item_int],\n",
    "            std_rating[item_int]\n",
    "        ]\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55a827",
   "metadata": {},
   "source": [
    "function 5: Normalize the feature vectors using Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ddf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(item_features, feature_means, feature_stds):\n",
    "    \"\"\"\n",
    "    Normalize each feature independently using Z-score:\n",
    "    Xi,f = (X_i,f - mean_f) / std_f\n",
    "    Returns a new dictionary with normalized features.\n",
    "    \"\"\"\n",
    "    normalized_features = {}\n",
    "    for item, features in item_features.items():\n",
    "        normalized = []\n",
    "        for j in range(len(features)):\n",
    "            if feature_stds[j] == 0:  # prevent division by zero\n",
    "                normalized.append(0.0)\n",
    "            else:\n",
    "                normalized.append((features[j] - feature_means[j]) / feature_stds[j])\n",
    "        normalized_features[item] = normalized\n",
    "    return normalized_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4a287",
   "metadata": {},
   "source": [
    "function 6: Compute mean of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_means(item_features):\n",
    "   \n",
    "    n_features = len(next(iter(item_features.values())))\n",
    "    feature_sums = [0.0] * n_features\n",
    "    n_items = len(item_features)\n",
    "\n",
    "    for features in item_features.values():\n",
    "        for j in range(n_features):\n",
    "            feature_sums[j] += features[j]\n",
    "\n",
    "    feature_means = [s / n_items for s in feature_sums]\n",
    "    return feature_means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950413e",
   "metadata": {},
   "source": [
    "function 7: Compute standard deviation of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_feature_stds(item_features, feature_means):\n",
    "    \n",
    "    n_features = len(feature_means)\n",
    "    n_items = len(item_features)\n",
    "    variance_sums = [0.0] * n_features\n",
    "\n",
    "    for features in item_features.values():\n",
    "        for j in range(n_features):\n",
    "            variance_sums[j] += (features[j] - feature_means[j]) ** 2\n",
    "\n",
    "    feature_stds = [math.sqrt(v / n_items) for v in variance_sums]\n",
    "    return feature_stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f33c03",
   "metadata": {},
   "source": [
    "function 8: Compute Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance between two vectors.\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(vec1, vec2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d426096",
   "metadata": {},
   "source": [
    "function 9: Initialize centroids randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def initialize_centroids(data, K):\n",
    "    \"\"\"\n",
    "    Randomly select K items as initial centroids.\n",
    "    Input: data = dict {item_id: feature_vector}\n",
    "    Output: list of centroid vectors\n",
    "    \"\"\"\n",
    "    all_features = list(data.values())\n",
    "    return random.sample(all_features, K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984ab93",
   "metadata": {},
   "source": [
    "function 10: Assign items to nearest centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(data, centroids):\n",
    "    \"\"\"\n",
    "    Assign each item to the nearest centroid.\n",
    "    Returns: dict {movieId: cluster_index}\n",
    "    \"\"\"\n",
    "    assignments = {}\n",
    "    for movieId, features in data.items():\n",
    "        distances = [euclidean_distance(features, c) for c in centroids]\n",
    "        cluster_index = distances.index(min(distances))\n",
    "        assignments[movieId] = cluster_index\n",
    "    return assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d53d2",
   "metadata": {},
   "source": [
    "function 11: Update centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centroids(data, assignments, K):\n",
    "    \"\"\"\n",
    "    Compute new centroids as mean of assigned items.\n",
    "    \"\"\"\n",
    "    n_features = len(next(iter(data.values())))\n",
    "    centroids = [[0.0] * n_features for _ in range(K)]\n",
    "    counts = [0] * K\n",
    "\n",
    "    for movieId, cluster_index in assignments.items():\n",
    "        features = data[movieId]\n",
    "        for j in range(n_features):\n",
    "            centroids[cluster_index][j] += features[j]\n",
    "        counts[cluster_index] += 1\n",
    "\n",
    "    for i in range(K):\n",
    "        if counts[i] > 0:\n",
    "            centroids[i] = [x / counts[i] for x in centroids[i]]\n",
    "        else:\n",
    "            # If a cluster gets no items, reinitialize randomly\n",
    "            centroids[i] = list(random.choice(list(data.values())))\n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ba640",
   "metadata": {},
   "source": [
    "function 12: Compute WCSS (within-cluster sum of squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eaabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wcss(data, assignments, centroids):\n",
    "    \"\"\"\n",
    "    Compute total WCSS for all clusters.\n",
    "    \"\"\"\n",
    "    wcss = 0.0\n",
    "    for movieId, cluster_index in assignments.items():\n",
    "        wcss += euclidean_distance(data[movieId], centroids[cluster_index]) ** 2\n",
    "    return wcss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dee392",
   "metadata": {},
   "source": [
    "function 13: Compute silhouette score (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_silhouette_score(data, assignments, K):\n",
    "    \"\"\"\n",
    "    Compute the silhouette score manually.\n",
    "    For each item i:\n",
    "      a(i) = average distance to other items in the same cluster\n",
    "      b(i) = minimum average distance to items in other clusters\n",
    "      s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
    "    Returns average silhouette over all items.\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    cluster_items = defaultdict(list)\n",
    "    for movieId, cluster_index in assignments.items():\n",
    "        cluster_items[cluster_index].append(movieId)\n",
    "\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for movieId, cluster_index in assignments.items():\n",
    "        current_vec = data[movieId]\n",
    "\n",
    "        # a(i): average distance to items in same cluster\n",
    "        same_cluster = [data[other] for other in cluster_items[cluster_index] if other != movieId]\n",
    "        if len(same_cluster) == 0:\n",
    "            a_i = 0\n",
    "        else:\n",
    "            a_i = sum(euclidean_distance(current_vec, o) for o in same_cluster) / len(same_cluster)\n",
    "\n",
    "        # b(i): minimum average distance to other clusters\n",
    "        b_i = float('inf')\n",
    "        for other_cluster_index, items in cluster_items.items():\n",
    "            if other_cluster_index == cluster_index:\n",
    "                continue\n",
    "            avg_dist = sum(euclidean_distance(current_vec, data[other]) for other in items) / len(items)\n",
    "            if avg_dist < b_i:\n",
    "                b_i = avg_dist\n",
    "\n",
    "        s_i = 0 if max(a_i, b_i) == 0 else (b_i - a_i) / max(a_i, b_i)\n",
    "        silhouette_scores.append(s_i)\n",
    "\n",
    "    return sum(silhouette_scores) / len(silhouette_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff8c5d",
   "metadata": {},
   "source": [
    "function 14: K-means usage function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(data, K, max_iters=100):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering manually.\n",
    "    Returns: centroids, assignments, WCSS, silhouette\n",
    "    \"\"\"\n",
    "    centroids = initialize_centroids(data, K)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        assignments = assign_clusters(data, centroids)\n",
    "        new_centroids = update_centroids(data, assignments, K)\n",
    "\n",
    "        # stop if centroids do not change\n",
    "        if all(\n",
    "            euclidean_distance(new_centroids[i], centroids[i]) < 1e-6 \n",
    "            for i in range(K)\n",
    "        ):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    wcss = compute_wcss(data, assignments, centroids)\n",
    "    silhouette = compute_silhouette_score(data, assignments, K)\n",
    "    return centroids, assignments, wcss, silhouette\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2182cf",
   "metadata": {},
   "source": [
    "function 15: Plot Elbow curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc034e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_elbow_wcss(metrics_df):\n",
    "    \"\"\"\n",
    "    Plot the elbow curve using WCSS for different K values.\n",
    "    Input: metrics_df with columns ['K', 'WCSS']\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(metrics_df['K'], metrics_df['WCSS'], 'o-', color='blue', linewidth=2)\n",
    "    plt.title(\"Elbow Method - WCSS vs K\")\n",
    "    plt.xlabel(\"Number of Clusters K\")\n",
    "    plt.ylabel(\"WCSS\")\n",
    "    plt.xticks(metrics_df['K'])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881b60b",
   "metadata": {},
   "source": [
    "function 16: Plot Silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette(metrics_df):\n",
    "    \"\"\"\n",
    "    Plot silhouette scores for different K values.\n",
    "    Input: metrics_df with columns ['K', 'Silhouette']\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(metrics_df['K'], metrics_df['Silhouette'], 'o-', color='green', linewidth=2)\n",
    "    plt.title(\"Silhouette Score vs K\")\n",
    "    plt.xlabel(\"Number of Clusters K\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.xticks(metrics_df['K'])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8bf67",
   "metadata": {},
   "source": [
    "function 17: Compute average number of raters per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_num_raters_per_cluster(assignments, num_raters):\n",
    "    \"\"\"\n",
    "    Compute the average number of raters for items in each cluster.\n",
    "    assignments: dict {item_id: cluster_index}\n",
    "    num_raters: dict {item_id: num_raters}\n",
    "    Returns: dict {cluster_index: avg_num_raters}\n",
    "    \"\"\"\n",
    "    cluster_raters = {}\n",
    "    cluster_counts = {}\n",
    "\n",
    "    for movieId, cluster in assignments.items():\n",
    "        if cluster not in cluster_raters:\n",
    "            cluster_raters[cluster] = 0\n",
    "            cluster_counts[cluster] = 0\n",
    "        cluster_raters[cluster] += num_raters[movieId]\n",
    "        cluster_counts[cluster] += 1\n",
    "\n",
    "    avg_raters_per_cluster = {}\n",
    "    for cluster in cluster_raters:\n",
    "        avg_raters_per_cluster[cluster] = cluster_raters[cluster] / cluster_counts[cluster]\n",
    "\n",
    "    return avg_raters_per_cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05373897",
   "metadata": {},
   "source": [
    "functoin 18: Classify clusters (popular/niche/long-tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763adf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_clusters(avg_raters_per_cluster):\n",
    "    \"\"\"\n",
    "    Classify clusters based on average number of raters:\n",
    "    - 'popular item': high num_raters\n",
    "    - 'niche item': low num_raters\n",
    "    - 'long-tail item': very few raters\n",
    "    Returns: dict {cluster_index: category}\n",
    "    \"\"\"\n",
    "    categories = {}\n",
    "    values = list(avg_raters_per_cluster.values())\n",
    "    max_raters = max(values)\n",
    "    min_raters = min(values)\n",
    "    range_raters = max_raters - min_raters\n",
    "\n",
    "    for cluster, avg_raters in avg_raters_per_cluster.items():\n",
    "        if avg_raters >= min_raters + 0.66 * range_raters:\n",
    "            categories[cluster] = 'popular item'\n",
    "        elif avg_raters <= min_raters + 0.33 * range_raters:\n",
    "            categories[cluster] = 'long-tail item'\n",
    "        else:\n",
    "            categories[cluster] = 'niche item'\n",
    "\n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4db064",
   "metadata": {},
   "source": [
    "function 19: Visualize distribution of items across clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c03f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_items_per_cluster(assignments):\n",
    "    \"\"\"\n",
    "    Plot the distribution of items across clusters.\n",
    "    assignments: dict {item_id: cluster_index}\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cluster_counts = Counter(assignments.values())\n",
    "    clusters = sorted(cluster_counts.keys())\n",
    "    counts = [cluster_counts[c] for c in clusters]\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(clusters, counts, color='skyblue')\n",
    "    plt.xlabel(\"Cluster Index\")\n",
    "    plt.ylabel(\"Number of Items\")\n",
    "    plt.title(\"Distribution of Items Across Clusters\")\n",
    "    plt.xticks(clusters)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11adfe",
   "metadata": {},
   "source": [
    "function 20: Plot distribution of number of raters per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b88ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raters_distribution_manual(df, cluster_col='cluster', raters_col='num_raters'):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    clusters = df[cluster_col].unique()  # <- use actual cluster IDs\n",
    "    clusters.sort()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        cluster_data = df[df[cluster_col] == cluster]\n",
    "        plt.hist(cluster_data[raters_col], alpha=0.5, label=f'Cluster {cluster}')\n",
    "    \n",
    "    plt.xlabel('Number of Raters')\n",
    "    plt.ylabel('Count of Items')\n",
    "    plt.title('Distribution of Raters per Cluster')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32d536",
   "metadata": {},
   "source": [
    "function 21: Cluster popularity summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_popularity_summary_manual(df, cluster_col='cluster', raters_col='num_raters'):\n",
    "    summary_list = []\n",
    "    clusters = df[cluster_col].unique()\n",
    "    clusters.sort()  # optional: sort ascending\n",
    "\n",
    "    for cluster in clusters:\n",
    "        cluster_df = df[df[cluster_col] == cluster]\n",
    "        num_items = len(cluster_df)\n",
    "        total_raters = cluster_df[raters_col].sum()\n",
    "        avg_raters = cluster_df[raters_col].mean()\n",
    "        summary_list.append({\n",
    "            'cluster': cluster,\n",
    "            'num_items': num_items,\n",
    "            'total_raters': total_raters,\n",
    "            'avg_raters': avg_raters\n",
    "        })\n",
    "\n",
    "    return summary_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec5b005",
   "metadata": {},
   "source": [
    "function 22: Head vs Tail distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42041258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_head_tail_distribution_manual(df, cluster_col='cluster', raters_col='num_raters', head_percent=0.2):\n",
    "    # Sort items by number of raters\n",
    "    df_sorted = df.sort_values(raters_col, ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Determine cutoff for head\n",
    "    head_cutoff = int(len(df) * head_percent)\n",
    "    \n",
    "    head_items = df_sorted.iloc[:head_cutoff]\n",
    "    tail_items = df_sorted.iloc[head_cutoff:]\n",
    "    \n",
    "    # Use actual cluster values\n",
    "    clusters = df[cluster_col].unique()\n",
    "    clusters.sort()\n",
    "    \n",
    "    distribution = {}\n",
    "    for cluster in clusters:\n",
    "        head_count = len(head_items[head_items[cluster_col] == cluster])\n",
    "        tail_count = len(tail_items[tail_items[cluster_col] == cluster])\n",
    "        distribution[cluster] = {'head': head_count, 'tail': tail_count}\n",
    "    \n",
    "    return distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eaf82",
   "metadata": {},
   "source": [
    "function 23: get cluster of a target item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_cluster(movieId, assignments):\n",
    "    \"\"\"\n",
    "    Returns the cluster assignment of a given item.\n",
    "    \n",
    "    item_id: the item to check\n",
    "    assignments: dictionary mapping item_id -> cluster\n",
    "    \"\"\"\n",
    "    return assignments[movieId]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557c9ff",
   "metadata": {},
   "source": [
    "fucntion 24: djusted Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_cosine_similarity(item1_ratings, item2_ratings, user_avg_ratings):\n",
    "    \"\"\"\n",
    "    Computes the Adjusted Cosine similarity between two items.\n",
    "    \n",
    "    item1_ratings, item2_ratings: dictionaries {user_id: rating}\n",
    "    user_avg_ratings: dictionary {user_id: avg rating}\n",
    "    \"\"\"\n",
    "    numerator = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    common_users = set(item1_ratings.keys()).intersection(set(item2_ratings.keys()))\n",
    "    \n",
    "    if not common_users:\n",
    "        return 0  # No common users\n",
    "    \n",
    "    for user in common_users:\n",
    "        dev1 = item1_ratings[user] - user_avg_ratings[user]\n",
    "        dev2 = item2_ratings[user] - user_avg_ratings[user]\n",
    "        numerator += dev1 * dev2\n",
    "        denom1 += dev1 ** 2\n",
    "        denom2 += dev2 ** 2\n",
    "    \n",
    "    if denom1 == 0 or denom2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    return numerator / ((denom1 ** 0.5) * (denom2 ** 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805aefb",
   "metadata": {},
   "source": [
    "function 25: Function to select top N% similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee088b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_similar(sim_dict, top_percent=0.2):\n",
    "    \"\"\"\n",
    "    Selects the top 'top_percent' most similar items from a similarity dictionary.\n",
    "    \n",
    "    sim_dict: {item_id: similarity_value}\n",
    "    top_percent: fraction to select\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(sim_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_n = max(1, int(len(sorted_items) * top_percent))\n",
    "    return dict(sorted_items[:top_n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794bece",
   "metadata": {},
   "source": [
    "function 26: Predict rating for a user for a target item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac95615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, target_item, similar_items, ratings_data, user_avg_ratings):\n",
    "    \"\"\"\n",
    "    Predicts rating using item-based collaborative filtering with Adjusted Cosine.\n",
    "    \n",
    "    user_id: target user\n",
    "    target_item: target item\n",
    "    similar_items: dict {item_id: similarity}\n",
    "    ratings_data: dict {item_id: {user_id: rating}}\n",
    "    user_avg_ratings: dict {user_id: avg rating}\n",
    "    \"\"\"\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for sim_item, sim in similar_items.items():\n",
    "        if user_id in ratings_data[sim_item]:\n",
    "            numerator += sim * (ratings_data[sim_item][user_id] - user_avg_ratings[user_id])\n",
    "            denominator += abs(sim)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return user_avg_ratings[user_id]  # fallback to user's average\n",
    "    \n",
    "    return user_avg_ratings[user_id] + numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e0c42",
   "metadata": {},
   "source": [
    "function 27: create per-user rating dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f44a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_item_ratings(assignments_optimal, average_ri, avg_rating):\n",
    "    \"\"\"\n",
    "    Build a dictionary of per-item ratings per user.\n",
    "\n",
    "    Returns:\n",
    "    ratings_data = {item_id: {user_id: rating}}\n",
    "    \"\"\"\n",
    "    ratings_data = {}\n",
    "    \n",
    "    # average_ri is a Series: index = user_id, value = user avg rating\n",
    "    user_avg = average_ri.to_dict()\n",
    "    \n",
    "    # For each item\n",
    "    for item in assignments_optimal:\n",
    "        # For this example, assume every user rated every item as the item's average\n",
    "        ratings_data[item] = {}\n",
    "        for user_id in user_avg:\n",
    "            ratings_data[item][user_id] = avg_rating[item]  # or use a randomized approach if needed\n",
    "    \n",
    "    return ratings_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4efd7",
   "metadata": {},
   "source": [
    "function 29: Predict ratings using non-clustering item CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_non_cluster(user_id, target_item, ratings_data, user_avg_ratings):\n",
    "    \"\"\"\n",
    "    Predict rating using item-based CF without clustering.\n",
    "    Uses Adjusted Cosine similarity with all other items.\n",
    "    \"\"\"\n",
    "    sim_dict = {}\n",
    "    \n",
    "    # Compute similarity between target_item and all other items\n",
    "    for other_item in ratings_data:\n",
    "        if other_item == target_item:\n",
    "            continue\n",
    "        sim = adjusted_cosine_similarity(\n",
    "            ratings_data[other_item],\n",
    "            ratings_data[target_item],\n",
    "            user_avg_ratings\n",
    "        )\n",
    "        sim_dict[other_item] = sim\n",
    "    \n",
    "    # Select top 20% similar items\n",
    "    top_sim_items = select_top_similar(sim_dict, top_percent=0.2)\n",
    "    \n",
    "    # Predict rating\n",
    "    return predict_rating(user_id, target_item, top_sim_items, ratings_data, user_avg_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a165db",
   "metadata": {},
   "source": [
    "function 30: compute prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction_errors(actual_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Compute prediction error for each user-item pair.\n",
    "    \n",
    "    actual_ratings: {user_id: {item_id: actual_rating}}\n",
    "    predicted_ratings: {user_id: {item_id: predicted_rating}}\n",
    "    \n",
    "    Returns: {user_id: {item_id: error}}\n",
    "    \"\"\"\n",
    "    errors = {}\n",
    "    for user in predicted_ratings:\n",
    "        errors[user] = {}\n",
    "        for item in predicted_ratings[user]:\n",
    "            actual = actual_ratings[user].get(item, None)\n",
    "            if actual is not None:\n",
    "                errors[user][item] = actual - predicted_ratings[user][item]\n",
    "            else:\n",
    "                errors[user][item] = None  # or skip\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062424c",
   "metadata": {},
   "source": [
    "function 31: Identify long-tail items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5345b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_tail_items(num_raters, percentile=20):\n",
    "    sorted_items = sorted(num_raters.items(), key=lambda x: x[1])\n",
    "    n = max(1, int(len(sorted_items) * percentile / 100))\n",
    "    return [item for item, _ in sorted_items[:n]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c311d5f",
   "metadata": {},
   "source": [
    "function 32: Count similar items for a target item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbe62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similar_items(target_item, similarity_dict, top_percent=0.2):\n",
    "    \"\"\"\n",
    "    Returns the number of top similar items for a target item.\n",
    "    \n",
    "    target_item: item_id\n",
    "    similarity_dict: dict {item_id: {other_item: similarity}}\n",
    "    top_percent: fraction to select  \n",
    "    \"\"\"\n",
    "    top_items = select_top_similar(similarity_dict[target_item], top_percent)\n",
    "    return len(top_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5685c9",
   "metadata": {},
   "source": [
    "function 33: Compute reliability for a set of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_abs_error_items(errors, items):\n",
    "    \"\"\"\n",
    "    Compute average absolute error for a subset of items.\n",
    "    \n",
    "    errors: {user_id: {item_id: error}}\n",
    "    items: list of item_ids\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for user in errors:\n",
    "        for item in items:\n",
    "            if item in errors[user] and errors[user][item] is not None:\n",
    "                total += abs(errors[user][item])\n",
    "                count += 1\n",
    "    return total / count if count > 0 else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c0adf6",
   "metadata": {},
   "source": [
    " Function 34: Reduction in similarity computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Function: Compute similarity reduction due to clustering\n",
    "# ------------------------------\n",
    "def compute_similarity_reduction(cluster_item_counts):\n",
    "    \"\"\"\n",
    "    cluster_item_counts: list of number of items per cluster\n",
    "    Returns the reduction in similarity computations due to clustering\n",
    "    \"\"\"\n",
    "    total_items = sum(cluster_item_counts)\n",
    "    total_pairs_no_cluster = total_items * (total_items - 1) / 2\n",
    "    total_pairs_clustered = sum(n * (n - 1) / 2 for n in cluster_item_counts)\n",
    "    reduction = 1 - (total_pairs_clustered / total_pairs_no_cluster)\n",
    "    return reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb41e95",
   "metadata": {},
   "source": [
    "Function 35: Compute speedup factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Function: Compute speedup factor compared to non-clustering CF\n",
    "# ------------------------------\n",
    "def compute_speedup_factor(sim_computations_no_cluster, sim_computations_clustered):\n",
    "    \"\"\"\n",
    "    sim_computations_no_cluster: total similarity computations without clustering\n",
    "    sim_computations_clustered: total similarity computations with clustering\n",
    "    Returns the speedup factor\n",
    "    \"\"\"\n",
    "    if sim_computations_clustered == 0:\n",
    "        return float('inf')  # Avoid division by zero\n",
    "    return sim_computations_no_cluster / sim_computations_clustered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a59f9",
   "metadata": {},
   "source": [
    "Function 36: Compare speedup for item vs user clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8572f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Function: Compare speedup factor between item-based and user-based clustering\n",
    "# ------------------------------\n",
    "def compare_speedup_item_user(item_cluster_counts, user_cluster_counts):\n",
    "    \"\"\"\n",
    "    item_cluster_counts: list of number of items per item-cluster\n",
    "    user_cluster_counts: list of number of users per user-cluster\n",
    "    Returns speedup factors for items and users\n",
    "    \"\"\"\n",
    "    # Compute total pairs for item-based CF\n",
    "    total_items = sum(item_cluster_counts)\n",
    "    total_pairs_items_no_cluster = total_items * (total_items - 1) / 2\n",
    "    total_pairs_items_clustered = sum(n * (n - 1) / 2 for n in item_cluster_counts)\n",
    "    speedup_items = total_pairs_items_no_cluster / total_pairs_items_clustered\n",
    "\n",
    "    # Compute total pairs for user-based CF\n",
    "    total_users = sum(user_cluster_counts)\n",
    "    total_pairs_users_no_cluster = total_users * (total_users - 1) / 2\n",
    "    total_pairs_users_clustered = sum(n * (n - 1) / 2 for n in user_cluster_counts)\n",
    "    speedup_users = total_pairs_users_no_cluster / total_pairs_users_clustered\n",
    "\n",
    "    return speedup_items, speedup_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5731c",
   "metadata": {},
   "source": [
    "Function 37: Compute average prediction error per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Function 11a: Average prediction error per cluster\n",
    "# ------------------------------\n",
    "def compute_avg_error_per_cluster(df_items, clustering_cf_errors):\n",
    "    \"\"\"\n",
    "    Compute the average prediction error for each cluster.\n",
    "\n",
    "    Parameters:\n",
    "        df_items: DataFrame with columns ['movieId', 'cluster', ...]\n",
    "        clustering_cf_errors: dict {movieId: error_value} of prediction errors\n",
    "\n",
    "    Returns:\n",
    "        dict {cluster_id: avg_error}\n",
    "    \"\"\"\n",
    "    cluster_errors = {}\n",
    "    for cluster_id in df_items['cluster'].unique():\n",
    "        items_in_cluster = df_items[df_items['cluster'] == cluster_id]['movieId']\n",
    "        errors = [clustering_cf_errors[item] for item in items_in_cluster if item in clustering_cf_errors]\n",
    "        if errors:\n",
    "            cluster_errors[cluster_id] = sum(errors) / len(errors)\n",
    "        else:\n",
    "            cluster_errors[cluster_id] = None  # or np.nan if preferred\n",
    "    return cluster_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2048d",
   "metadata": {},
   "source": [
    "Function 38: Group clusters by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Function 11b: Group clusters by size\n",
    "# ------------------------------\n",
    "def group_clusters_by_size(df_items):\n",
    "    \"\"\"\n",
    "    Count the number of items in each cluster.\n",
    "\n",
    "    Returns:\n",
    "        dict {cluster_id: num_items}\n",
    "    \"\"\"\n",
    "    cluster_sizes = df_items.groupby('cluster').size().to_dict()\n",
    "    return cluster_sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a87e6",
   "metadata": {},
   "source": [
    "Function 39: Analyze accuracy vs cluster size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Function 11c: Analyze relationship between cluster size and prediction error\n",
    "# ------------------------------\n",
    "def accuracy_vs_cluster_size(cluster_sizes, cluster_errors):\n",
    "    \"\"\"\n",
    "    Create a summary of cluster size vs average prediction error.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: [(cluster_id, size, avg_error)]\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    for cluster_id, size in cluster_sizes.items():\n",
    "        avg_error = cluster_errors.get(cluster_id, None)\n",
    "        summary.append((cluster_id, size, avg_error))\n",
    "    return sorted(summary, key=lambda x: x[1])  # sorted by cluster size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6645aee",
   "metadata": {},
   "source": [
    "Function 40: Count items per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aab1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_clusters_by_size(df_items):\n",
    "    cluster_sizes = df_items.groupby(\"cluster\")[\"movieId\"].count().to_dict()\n",
    "    return cluster_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf4e67",
   "metadata": {},
   "source": [
    "Function 41: Compute avg rating-prediction error per cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_error_per_cluster(df_items, item_errors):\n",
    "    # Merge error values into the dataframe\n",
    "    df = df_items.copy()\n",
    "    df[\"error\"] = df[\"movieId\"].map(item_errors)\n",
    "\n",
    "    # Compute average error per cluster\n",
    "    cluster_errors = df.groupby(\"cluster\")[\"error\"].mean().to_dict()\n",
    "    return cluster_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b005fc",
   "metadata": {},
   "source": [
    "Function 42: Combine cluster sizes & avg errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619969df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_vs_cluster_size(cluster_sizes, cluster_errors):\n",
    "    summary = []\n",
    "\n",
    "    for cid in cluster_sizes:\n",
    "        size = cluster_sizes.get(cid, 0)\n",
    "        err = cluster_errors.get(cid, None)\n",
    "        summary.append((cid, size, err))\n",
    "\n",
    "    # sort by cluster id\n",
    "    summary = sorted(summary, key=lambda x: x[0])\n",
    "    return summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
